#!/usr/bin/env python3
"""
Sistema de treinamento de IA local para AUTOBOT
Implementa integra√ß√£o com Ollama e ChromaDB para IA local completa
"""

import ollama
import chromadb
from sentence_transformers import SentenceTransformer
import json
import logging
from pathlib import Path
from typing import List, Dict, Any
import asyncio

# Configura√ß√£o de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AutobotLocalTrainer:
    """Sistema de treinamento de IA local para AUTOBOT"""
    
    def __init__(self, chroma_path: str = "IA/memoria_vetorial"):
        """
        Inicializa o sistema de treinamento de IA local
        
        Args:
            chroma_path: Caminho para armazenar a base de dados vetorial
        """
        try:
            self.ollama_client = ollama.Client()
            self.chroma_client = chromadb.PersistentClient(path=chroma_path)
            self.encoder = SentenceTransformer('all-MiniLM-L6-v2')
            logger.info("‚úÖ AutobotLocalTrainer inicializado com sucesso")
        except Exception as e:
            logger.error(f"‚ùå Erro ao inicializar AutobotLocalTrainer: {e}")
            raise
        
    def setup_ollama_models(self) -> Dict[str, str]:
        """
        Configura modelos Ollama locais essenciais
        
        Returns:
            Dict com status de cada modelo instalado
        """
        models = ['llama3', 'mistral', 'tinyllama']
        status = {}
        
        logger.info("ü¶ô Iniciando configura√ß√£o de modelos Ollama...")
        
        for model in models:
            try:
                logger.info(f"üì• Baixando modelo {model}...")
                self.ollama_client.pull(model)
                status[model] = "‚úÖ Instalado com sucesso"
                logger.info(f"‚úÖ Modelo {model} instalado")
            except Exception as e:
                status[model] = f"‚ö†Ô∏è Erro: {str(e)}"
                logger.error(f"‚ö†Ô∏è Erro ao instalar {model}: {e}")
        
        return status
    
    def create_knowledge_base(self, training_data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Cria base de conhecimento vetorial com dados de treinamento
        
        Args:
            training_data: Lista de dicion√°rios com 'pergunta', 'resposta' e 'fonte'
            
        Returns:
            Dict com status da cria√ß√£o da base de conhecimento
        """
        try:
            collection = self.chroma_client.get_or_create_collection("autobot_knowledge")
            
            logger.info(f"üìö Criando base de conhecimento com {len(training_data)} itens...")
            
            for i, data in enumerate(training_data):
                pergunta = data.get('pergunta', '')
                resposta = data.get('resposta', '')
                fonte = data.get('fonte', 'treinamento')
                
                if not pergunta or not resposta:
                    logger.warning(f"‚ö†Ô∏è Item {i} inv√°lido - pergunta ou resposta vazia")
                    continue
                
                # Cria embedding da pergunta
                embedding = self.encoder.encode(pergunta)
                
                # Adiciona √† cole√ß√£o
                collection.add(
                    embeddings=[embedding.tolist()],
                    documents=[resposta],
                    metadatas=[{"fonte": fonte, "pergunta": pergunta}],
                    ids=[f"doc_{i}"]
                )
            
            logger.info("‚úÖ Base de conhecimento criada com sucesso")
            return {
                "status": "success", 
                "message": f"Base de conhecimento criada com {len(training_data)} itens",
                "total_items": len(training_data)
            }
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao criar base de conhecimento: {e}")
            return {"status": "error", "erro": str(e)}
    
    def train_custom_model(self, exemplos_treinamento: str, nome_modelo: str = "autobot-personalizado") -> Dict[str, Any]:
        """
        Treina modelo personalizado baseado no AIEngine existente
        
        Args:
            exemplos_treinamento: String com exemplos de treinamento
            nome_modelo: Nome do modelo personalizado a ser criado
            
        Returns:
            Dict com status do treinamento
        """
        try:
            logger.info(f"üß† Iniciando treinamento do modelo {nome_modelo}...")
            
            # Cria modelfile personalizado
            modelfile = f"""FROM llama3
PARAMETER temperature 0.7
PARAMETER top_p 0.9
PARAMETER top_k 40

SYSTEM \"\"\"
Voc√™ √© o AUTOBOT, um assistente de IA especializado em:
- Automa√ß√£o de tarefas corporativas
- Integra√ß√£o com Bitrix24, IXCSOFT, Locaweb
- An√°lise de dados e m√©tricas empresariais
- Controle de sistemas via interface
- Processamento de documentos e OCR
- Automa√ß√£o com PyAutoGUI e Selenium

Suas caracter√≠sticas:
- Respostas precisas e t√©cnicas
- Foco em solu√ß√µes pr√°ticas
- Conhecimento em integra√ß√µes corporativas
- Expertise em automa√ß√£o de processos

Exemplos de treinamento:
{exemplos_treinamento}

Sempre forne√ßa respostas detalhadas e pr√°ticas para ajudar com automa√ß√£o e integra√ß√µes corporativas.
\"\"\"
"""
            
            # Cria o modelo personalizado
            self.ollama_client.create(model=nome_modelo, modelfile=modelfile)
            
            logger.info(f"‚úÖ Modelo {nome_modelo} criado com sucesso")
            return {
                "status": "success", 
                "modelo": nome_modelo,
                "message": f"Modelo {nome_modelo} treinado e dispon√≠vel"
            }
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao treinar modelo: {e}")
            return {"status": "error", "erro": str(e)}
    
    def test_model(self, modelo: str = "autobot-personalizado", pergunta: str = "Como posso automatizar uma tarefa?") -> Dict[str, Any]:
        """
        Testa um modelo treinado com uma pergunta de exemplo
        
        Args:
            modelo: Nome do modelo a ser testado
            pergunta: Pergunta de teste
            
        Returns:
            Dict com resposta do modelo e status
        """
        try:
            logger.info(f"üß™ Testando modelo {modelo}...")
            
            response = self.ollama_client.generate(
                model=modelo,
                prompt=pergunta
            )
            
            resposta = response.get('response', 'Sem resposta')
            
            logger.info(f"‚úÖ Teste do modelo {modelo} conclu√≠do")
            return {
                "status": "success",
                "modelo": modelo,
                "pergunta": pergunta,
                "resposta": resposta
            }
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao testar modelo: {e}")
            return {"status": "error", "erro": str(e)}
    
    def list_available_models(self) -> List[str]:
        """
        Lista modelos dispon√≠veis no Ollama
        
        Returns:
            Lista de nomes dos modelos dispon√≠veis
        """
        try:
            models = self.ollama_client.list()
            model_names = [model['name'] for model in models.get('models', [])]
            logger.info(f"üìã Modelos dispon√≠veis: {model_names}")
            return model_names
        except Exception as e:
            logger.error(f"‚ùå Erro ao listar modelos: {e}")
            return []
    
    def get_model_info(self, modelo: str) -> Dict[str, Any]:
        """
        Obt√©m informa√ß√µes detalhadas sobre um modelo
        
        Args:
            modelo: Nome do modelo
            
        Returns:
            Dict com informa√ß√µes do modelo
        """
        try:
            info = self.ollama_client.show(modelo)
            return {"status": "success", "info": info}
        except Exception as e:
            logger.error(f"‚ùå Erro ao obter info do modelo {modelo}: {e}")
            return {"status": "error", "erro": str(e)}

# Fun√ß√£o de teste para validar a instala√ß√£o
def test_installation():
    """Testa a instala√ß√£o e configura√ß√£o do sistema"""
    try:
        trainer = AutobotLocalTrainer()
        
        # Testa dados de exemplo
        dados_exemplo = [
            {
                "pergunta": "Como integrar com Bitrix24?",
                "resposta": "Para integrar com Bitrix24, use a API REST com webhook configurado para receber eventos em tempo real.",
                "fonte": "documentacao_bitrix"
            },
            {
                "pergunta": "Como automatizar click em bot√£o?",
                "resposta": "Use PyAutoGUI.click(x, y) para clicar em coordenadas espec√≠ficas ou pyautogui.click('imagem.png') para localizar por imagem.",
                "fonte": "automacao_gui"
            }
        ]
        
        # Cria base de conhecimento
        result = trainer.create_knowledge_base(dados_exemplo)
        print(f"Base de conhecimento: {result}")
        
        # Lista modelos
        models = trainer.list_available_models()
        print(f"Modelos dispon√≠veis: {models}")
        
        print("‚úÖ Teste de instala√ß√£o conclu√≠do com sucesso!")
        return True
        
    except Exception as e:
        print(f"‚ùå Erro no teste de instala√ß√£o: {e}")
        return False

if __name__ == "__main__":
    print("üß† AUTOBOT - Sistema de Treinamento de IA Local")
    print("=" * 50)
    
    if test_installation():
        print("\nüöÄ Sistema pronto para uso!")
        print("Execute: python -c 'from IA.treinamento.local_trainer import AutobotLocalTrainer; trainer = AutobotLocalTrainer()'")
    else:
        print("\n‚ö†Ô∏è Problemas na instala√ß√£o detectados. Verifique as depend√™ncias.")