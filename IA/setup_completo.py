#!/usr/bin/env python3
"""
Sistema de configuraÃ§Ã£o completa do AUTOBOT IA Local
VersÃ£o Enterprise com todas as funcionalidades
"""

import os
import sys
import subprocess
import json
import logging
from pathlib import Path
from datetime import datetime
import platform
import psutil
import requests
from typing import Dict, List, Optional, Tuple
import yaml

class AutobotSetupManager:
    """Gerenciador principal de configuraÃ§Ã£o do AUTOBOT"""
    
    def __init__(self):
        self.root_path = Path(__file__).parent.parent
        self.logger = self._setup_logging()
        self.config = self._load_config()
        self.system_info = self._detect_system()
        
    def _setup_logging(self) -> logging.Logger:
        """Configura sistema de logging avanÃ§ado"""
        log_dir = Path("IA/logs")
        log_dir.mkdir(parents=True, exist_ok=True)
        
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        
        logger = logging.getLogger('autobot_setup')
        logger.setLevel(logging.INFO)
        
        # Handler para arquivo
        file_handler = logging.FileHandler(log_dir / 'setup.log')
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)
        
        # Handler para console
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(formatter)
        logger.addHandler(console_handler)
        
        return logger
    
    def _load_config(self) -> Dict:
        """Carrega configuraÃ§Ã£o do sistema"""
        config_path = Path("IA/config.yaml")
        
        if config_path.exists():
            with open(config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        
        # ConfiguraÃ§Ã£o padrÃ£o
        default_config = {
            'ollama': {
                'host': 'localhost',
                'port': 11434,
                'models': ['llama3.2', 'mistral', 'tinyllama']
            },
            'chromadb': {
                'path': 'IA/memoria_conversas',
                'collection_prefix': 'autobot'
            },
            'redis': {
                'host': 'localhost',
                'port': 6379,
                'db': 0
            },
            'ai': {
                'embedding_model': 'all-MiniLM-L6-v2',
                'max_context_length': 4096,
                'temperature': 0.7
            }
        }
        
        # Salva configuraÃ§Ã£o padrÃ£o
        config_path.parent.mkdir(parents=True, exist_ok=True)
        with open(config_path, 'w', encoding='utf-8') as f:
            yaml.dump(default_config, f, default_flow_style=False)
        
        return default_config
    
    def _detect_system(self) -> Dict:
        """Detecta especificaÃ§Ãµes do sistema"""
        return {
            'os': platform.system(),
            'cpu_cores': psutil.cpu_count(),
            'memory_gb': round(psutil.virtual_memory().total / (1024**3)),
            'disk_free_gb': round(psutil.disk_usage('/').free / (1024**3)),
            'python_version': platform.python_version(),
            'has_gpu': self._detect_gpu(),
            'docker_available': self._check_docker(),
        }
    
    def _detect_gpu(self) -> bool:
        """Detecta se hÃ¡ GPU NVIDIA disponÃ­vel"""
        try:
            subprocess.run(['nvidia-smi'], capture_output=True, check=True)
            return True
        except (subprocess.CalledProcessError, FileNotFoundError):
            return False
    
    def _check_docker(self) -> bool:
        """Verifica se Docker estÃ¡ disponÃ­vel"""
        try:
            subprocess.run(['docker', '--version'], capture_output=True, check=True)
            return True
        except (subprocess.CalledProcessError, FileNotFoundError):
            return False
    
    def setup_full_enterprise(self):
        """ConfiguraÃ§Ã£o completa enterprise"""
        self.logger.info("ğŸš€ Iniciando configuraÃ§Ã£o AUTOBOT Enterprise")
        
        # Fase 1: Estrutura
        self._create_directory_structure()
        
        # Fase 2: DependÃªncias
        self._install_dependencies()
        
        # Fase 3: Modelos IA
        self._setup_ai_models()
        
        # Fase 4: Banco de dados
        self._setup_databases()
        
        # Fase 5: Docker
        self._setup_docker_environment()
        
        # Fase 6: Testes
        self._run_initial_tests()
        
        self.logger.info("âœ… ConfiguraÃ§Ã£o completa finalizada!")
    
    def _create_directory_structure(self):
        """Cria estrutura de diretÃ³rios necessÃ¡ria"""
        directories = [
            'IA/logs',
            'IA/modelos',
            'IA/memoria_conversas',
            'IA/treinamento',
            'autobot/integraÃ§Ãµes',
            'web/src/components',
            'docker/ai-services',
            'tests/ai'
        ]
        
        for directory in directories:
            Path(directory).mkdir(parents=True, exist_ok=True)
            self.logger.info(f"ğŸ“ DiretÃ³rio criado: {directory}")
    
    def _install_dependencies(self):
        """Instala dependÃªncias Python"""
        try:
            self.logger.info("ğŸ“¦ Instalando dependÃªncias...")
            subprocess.run([
                sys.executable, '-m', 'pip', 'install', '-r', 'requirements.txt'
            ], check=True, capture_output=True)
            self.logger.info("âœ… DependÃªncias instaladas com sucesso")
        except subprocess.CalledProcessError as e:
            self.logger.error(f"âŒ Erro ao instalar dependÃªncias: {e}")
    
    def _setup_ai_models(self):
        """Configura modelos de IA"""
        self.logger.info("ğŸ¤– Configurando modelos de IA...")
        
        # Verifica se Ollama estÃ¡ disponÃ­vel
        try:
            subprocess.run(['ollama', 'version'], check=True, capture_output=True)
            self.logger.info("âœ… Ollama detectado")
            
            # Instala modelos bÃ¡sicos
            models = self.config['ollama']['models']
            for model in models:
                try:
                    self.logger.info(f"ğŸ“¥ Baixando modelo: {model}")
                    subprocess.run(['ollama', 'pull', model], check=True)
                    self.logger.info(f"âœ… Modelo {model} instalado")
                except subprocess.CalledProcessError:
                    self.logger.warning(f"âš ï¸ Falha ao instalar modelo: {model}")
        
        except subprocess.CalledProcessError:
            self.logger.warning("âš ï¸ Ollama nÃ£o disponÃ­vel. Instale manualmente.")
    
    def _setup_databases(self):
        """Configura bancos de dados"""
        self.logger.info("ğŸ—„ï¸ Configurando bancos de dados...")
        
        # ChromaDB - configuraÃ§Ã£o bÃ¡sica
        chroma_path = Path(self.config['chromadb']['path'])
        chroma_path.mkdir(parents=True, exist_ok=True)
        self.logger.info(f"âœ… ChromaDB configurado em: {chroma_path}")
        
        # Redis - verifica disponibilidade
        try:
            import redis
            r = redis.Redis(
                host=self.config['redis']['host'],
                port=self.config['redis']['port'],
                db=self.config['redis']['db']
            )
            r.ping()
            self.logger.info("âœ… Redis conectado com sucesso")
        except Exception:
            self.logger.warning("âš ï¸ Redis nÃ£o disponÃ­vel. FuncionarÃ¡ sem cache.")
    
    def _setup_docker_environment(self):
        """Configura ambiente Docker"""
        if not self.system_info['docker_available']:
            self.logger.warning("âš ï¸ Docker nÃ£o disponÃ­vel")
            return
        
        self.logger.info("ğŸ³ Configurando ambiente Docker...")
        
        # Cria docker-compose.yml para serviÃ§os de IA
        docker_compose = {
            'version': '3.8',
            'services': {
                'redis': {
                    'image': 'redis:7-alpine',
                    'ports': ['6379:6379'],
                    'volumes': ['redis_data:/data']
                },
                'ollama': {
                    'image': 'ollama/ollama:latest',
                    'ports': ['11434:11434'],
                    'volumes': ['ollama_data:/root/.ollama']
                }
            },
            'volumes': {
                'redis_data': {},
                'ollama_data': {}
            }
        }
        
        docker_path = Path('docker/docker-compose.yml')
        docker_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(docker_path, 'w') as f:
            yaml.dump(docker_compose, f, default_flow_style=False)
        
        self.logger.info("âœ… Docker Compose configurado")
    
    def _run_initial_tests(self):
        """Executa testes iniciais do sistema"""
        self.logger.info("ğŸ§ª Executando testes iniciais...")
        
        # Teste bÃ¡sico de importaÃ§Ãµes
        try:
            import torch
            import chromadb
            from sentence_transformers import SentenceTransformer
            self.logger.info("âœ… Bibliotecas de IA importadas com sucesso")
        except ImportError as e:
            self.logger.error(f"âŒ Erro ao importar bibliotecas: {e}")
        
        # Teste de modelo de embeddings
        try:
            model = SentenceTransformer(self.config['ai']['embedding_model'])
            test_embedding = model.encode("Teste de embedding")
            self.logger.info(f"âœ… Modelo de embedding funcionando: {len(test_embedding)} dimensÃµes")
        except Exception as e:
            self.logger.error(f"âŒ Erro no modelo de embedding: {e}")
    
    def get_system_status(self) -> Dict:
        """Retorna status detalhado do sistema"""
        return {
            'timestamp': datetime.now().isoformat(),
            'system_info': self.system_info,
            'config': self.config,
            'services': {
                'ollama': self._check_service('ollama'),
                'redis': self._check_service('redis'),
                'chromadb': True  # ChromaDB Ã© sempre disponÃ­vel localmente
            }
        }
    
    def _check_service(self, service: str) -> bool:
        """Verifica se um serviÃ§o estÃ¡ disponÃ­vel"""
        if service == 'ollama':
            try:
                subprocess.run(['ollama', 'version'], check=True, capture_output=True)
                return True
            except subprocess.CalledProcessError:
                return False
        elif service == 'redis':
            try:
                import redis
                r = redis.Redis(
                    host=self.config['redis']['host'],
                    port=self.config['redis']['port']
                )
                r.ping()
                return True
            except Exception:
                return False
        return False

if __name__ == "__main__":
    setup_manager = AutobotSetupManager()
    
    if len(sys.argv) > 1 and sys.argv[1] == "--status":
        status = setup_manager.get_system_status()
        print(json.dumps(status, indent=2, ensure_ascii=False))
    else:
        setup_manager.setup_full_enterprise()